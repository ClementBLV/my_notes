
## Translation 

**[[BLEU]]** (**bilingual evaluation understudy**) is an algorithm for evaluating the quality of text which has been machine-translated. Quality is considered to be the correspondence between a machine's output and that of a human. BLEU is one of the most popular automated and inexpensive metrics.

Scores are calculated for individual translated segments—generally sentences—by comparing them with a set of good quality reference translations, hence need of parallels corpus . Those scores are then averaged over the whole corpus to reach an estimate of the translation's overall quality. Intelligibility or grammatical correctness are not taken into account.