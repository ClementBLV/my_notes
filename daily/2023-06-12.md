ideas to improve the results : 
- cosine similarity between the two embeddings of the sentenses
- frequense terms (TFIDF), overlapping ration of the words to identify weather a word in the first sentence also appear in the second one (Common Words ^2 /number of words ), **Levenshtein** distance, The longest matching word sequence against the first sentence [ref](https://www.researchgate.net/publication/334697989_Algorithm_to_Identify_the_Connection_between_Sentences/link/5d3ae3a7a6fdcc370a60be82/download) 
- entailment between the candidate and the nodes --> finetuner ? 
- generative model , see if its able to output one of teh possible candidate 


- idées to speed up le process de xml = 
-          initialisation au lieux d'initialiser sur un synset peut etre direct le faire sur la synset relation -> genre recupp toute la relation 

        takeaways = self.Bs_data.findAll('Synset') # all the words of the DataBase

        # loops  

        for eachtakeaway in takeaways:

                for relation in eachtakeaway.find_all('SynsetRelation'):  #
       dz
- same for the senses in remove_synset_from_word(self, synset_key:str, ): directly get the sense instead of teh take away 


Monday Goal 
- the program to downgrade the wordnet works but it is way to long according to tqdm it has to compile for 24 to 25 hours to only have a 10% downgrade so i will investigate (it was 28 hours before so i already managed to reduce it ahah ) ( it sucks cause i lunched it during the weekend but it has frozen in the middle )
- complete the notas section as José ask for 
- find indeas to get another metric in addition to sentence similarity 

